{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e564ee",
   "metadata": {},
   "source": [
    "# 01 · Data Preprocessing\n",
    "\n",
    "This notebook loads raw experiment logs, applies the **pre-registered exclusion rules**, cleans/derives variables, and exports a tidy dataset (`clean_data.csv`) for downstream analysis.\n",
    "\n",
    "**Inputs (expected):**\n",
    "- `../data/raw/participants.csv` (demographics, baseline trust)\n",
    "- `../data/raw/trials.csv` (one row per trial; timestamps, choices)\n",
    "- `../data/raw/post_task.csv` (post-task trust, NASA-TLX)\n",
    "\n",
    "**Outputs:**\n",
    "- `../data/derived/clean_data.csv`\n",
    "- `../data/derived/exclusions.csv` (list of excluded participants and reasons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_RAW = Path('../data/raw')\n",
    "DATA_DERIVED = Path('../data/derived')\n",
    "DATA_DERIVED.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca50359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data (adjust paths/filenames if needed)\n",
    "participants = pd.read_csv(DATA_RAW / 'participants.csv')\n",
    "trials = pd.read_csv(DATA_RAW / 'trials.csv')\n",
    "post_task = pd.read_csv(DATA_RAW / 'post_task.csv')\n",
    "print(participants.shape, trials.shape, post_task.shape)\n",
    "display(participants.head(3))\n",
    "display(trials.head(3))\n",
    "display(post_task.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d9d7f",
   "metadata": {},
   "source": [
    "## Apply preregistered exclusions\n",
    "\n",
    "- **Attention check failure** → exclude participant\n",
    "- **Completion ≤ 50% of trials** → exclude participant\n",
    "\n",
    "Document excluded IDs and the reason in `exclusions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6520e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag attention check failures (example column names; adjust to your schema)\n",
    "attn_fail = participants.query('attention_check_passed == 0')['participant_id']\n",
    "\n",
    "# Compute completion rate per participant\n",
    "trial_counts = trials.groupby('participant_id')['trial_id'].nunique()\n",
    "total_trials = trials['trial_id'].nunique()\n",
    "completion_rate = trial_counts / total_trials\n",
    "low_completion = completion_rate[completion_rate <= 0.5].index\n",
    "\n",
    "exclude_ids = pd.Index(attn_fail).union(low_completion)\n",
    "exclusions = pd.DataFrame({'participant_id': exclude_ids,\n",
    "                           'reason': ['attn_or_low_completion']*len(exclude_ids)})\n",
    "exclusions.to_csv(DATA_DERIVED / 'exclusions.csv', index=False)\n",
    "print(f'Excluded N={len(exclude_ids)} participants')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a71c4",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "Merge `participants`, `trials`, and `post_task` into a single long-format table.\n",
    "Ensure that **condition** is correctly typed as category, and compute any derived fields (e.g., decision time in seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to included participants\n",
    "incl_participants = participants[~participants['participant_id'].isin(exclude_ids)].copy()\n",
    "incl_trials = trials[trials['participant_id'].isin(incl_participants['participant_id'])].copy()\n",
    "incl_post = post_task[post_task['participant_id'].isin(incl_participants['participant_id'])].copy()\n",
    "\n",
    "# Example: derive decision_time_s from timestamps (assumes ms columns; adjust as needed)\n",
    "if {'ts_presented_ms','ts_decision_ms'}.issubset(incl_trials.columns):\n",
    "    incl_trials['decision_time_s'] = (incl_trials['ts_decision_ms'] - incl_trials['ts_presented_ms']) / 1000.0\n",
    "\n",
    "# Example: map numeric condition to labels if required\n",
    "condition_map = {0: 'A_Standard', 1: 'B_Explainable'}\n",
    "if incl_trials['condition'].dtype != 'O':\n",
    "    incl_trials['condition_label'] = incl_trials['condition'].map(condition_map)\n",
    "else:\n",
    "    incl_trials['condition_label'] = incl_trials['condition']\n",
    "\n",
    "# Aggregate per-participant outcomes (acceptance rate, mean decision time)\n",
    "agg = (incl_trials\n",
    "       .assign(accept=lambda d: (d['choice'].str.lower()=='accept').astype(int))\n",
    "       .groupby(['participant_id','condition_label'], as_index=False)\n",
    "       .agg(acceptance_rate=('accept','mean'),\n",
    "            mean_decision_time_s=('decision_time_s','mean')))\n",
    "\n",
    "# Merge baseline/post trust\n",
    "merged = (agg\n",
    "          .merge(incl_participants[['participant_id','trust_baseline']], on='participant_id', how='left')\n",
    "          .merge(incl_post[['participant_id','trust_post','nasa_tlx']], on='participant_id', how='left'))\n",
    "\n",
    "merged['acceptance_rate'] = (merged['acceptance_rate'] * 100).round(1)\n",
    "merged['condition_label'] = merged['condition_label'].astype('category')\n",
    "display(merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0eccc",
   "metadata": {},
   "source": [
    "## Save outputs\n",
    "Export the tidy dataset for analysis and tables/figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = DATA_DERIVED / 'clean_data.csv'\n",
    "merged.to_csv(outpath, index=False)\n",
    "print(f'Saved: {outpath.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c21cbf",
   "metadata": {},
   "source": [
    "> **Note:** If you cannot share real logs, commit a small *synthetic* `clean_data.csv` that follows the same schema to enable downstream notebooks to run."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
