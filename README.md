Humanâ€“AI Collaboration in Cybersecurity Incident Response

Evaluating LLM-Generated Explanations for Trust and Decision-Making

ğŸ“Œ Overview

This repository contains the code, data, and analysis materials for my MSc project on Humanâ€“AI collaboration in cybersecurity incident response (CSIR).
The project investigates whether GPT-4â€“generated explanations for alerts can improve trust, decision-making speed, and alert acceptance in simulated CSIR tasks.

The experiment compared two conditions:

Condition A (Standard AI): Alerts without explanations

Condition B (Explainable AI): Same alerts with short, natural language explanations generated by GPT-4

ğŸ“‚ Repository Structure
```
human-ai-csir/
â”‚
â”œâ”€â”€ stimuli/                  # Synthetic alerts & GPT-4 explanations
â”‚   â”œâ”€â”€ alerts.json
â”‚   â”œâ”€â”€ explanations.json
â”‚
â”œâ”€â”€ app/                      # Web experiment (Flask + JS/HTML)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ templates/
â”‚
â”œâ”€â”€ surveys/                  # Consent form & questionnaires
â”‚   â”œâ”€â”€ consent_form.pdf
â”‚   â”œâ”€â”€ pre_task_survey.md
â”‚   â”œâ”€â”€ post_task_survey.md
â”‚
â”œâ”€â”€ analysis/                 # Jupyter notebooks & figures
â”‚   â”œâ”€â”€ results.ipynb
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ trust_boxplot.png
â”‚   â”‚   â”œâ”€â”€ decision_time.png
â”‚   â”‚   â”œâ”€â”€ acceptance_rate.png
â”‚
â”œâ”€â”€ data/                     # Anonymized participant logs
â”‚   â”œâ”€â”€ sample_data.csv
â”‚
â”œâ”€â”€ docs/                     # Extra documentation (optional)
â”‚   â”œâ”€â”€ methodology.md
â”‚   â”œâ”€â”€ study_design_diagram.png
â”‚
â”œâ”€â”€ README.md                 # Project overview & instructions
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ LICENSE                   # License (MIT/Apache)

```

âš™ï¸ Installation

Clone the repo and install dependencies:
```
git clone https://github.com/your-username/human-ai-csir.git
cd human-ai-csir
pip install -r requirements.txt
```

â–¶ï¸ Running the Experiment

1. Start the Flask app:
```
python app/app.py
```
2. Open your browser at http://127.0.0.1:5000/
3. Complete the task trials (Condition A or B).
4. Logs will be stored in data/ as CSV.

ğŸ“Š Analysis

The analysis/results.ipynb notebook contains:

* Descriptive statistics
* Independent-samples t-tests / Mannâ€“Whitney tests
* Effect sizes & confidence intervals
* Boxplots and bar charts
Exported figures are saved in analysis/figures/.

ğŸ” Results (Pilot Study)

* Trust: Higher in the Explainable AI condition (significant, large effect).
* Decision Time: Faster with explanations (medium-to-large effect, marginal $p$).
* Acceptance Rate: Higher with explanations (medium effect, not fully significant).

ğŸ™ Acknowledgments

* University of Adelaide, MSc in Cybersecurity
* Participants who volunteered for the pilot study
* OpenAI GPT-4 API for explanation generation